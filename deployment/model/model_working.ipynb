{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import libraries\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_string_dtype\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialize data\"\"\"\n",
    "\n",
    "train_test_data = '../../../data/properties_filtered.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to load train-test data into a dataframe\"\"\"\n",
    "\n",
    "def load_train_test(train_test_data):\n",
    "    df_train_test = pd.read_csv(train_test_data)\n",
    "    return df_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to drop model training features that won't be used for modeling then sort dataframe\"\"\"\n",
    "\n",
    "def train_test_features(df_train_test):\n",
    "    df_train_test.drop(df_train_test.columns[13:20], inplace=True, axis=1)\n",
    "    df_train_test.drop(df_train_test.columns[5:8], inplace=True, axis=1)\n",
    "    df_train_test.drop(df_train_test.columns[1:4], inplace=True, axis=1)\n",
    "    df_train_test = df_train_test.reindex(sorted(df_train_test.columns), axis=1)   #sort features alphabetically\n",
    "    return df_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to transform train-test values\"\"\"\n",
    "\n",
    "def train_test_values(df_train_test_features):\n",
    "    df_train_test_features[\"postalCode\"] = df_train_test_features[\"postalCode\"].astype(str)   #convert 'postalCode' to string type\n",
    "    df_train_test_features[\"kitchenType\"] = df_train_test_features[\"kitchenType\"].replace([1, 2], 0)   #convert 'kitchenType' to binary (bool)\n",
    "    df_train_test_features[\"kitchenType\"] = df_train_test_features[\"kitchenType\"].replace([3, 4, 5, 6, 7, 8], 1)\n",
    "    return df_train_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to define categorical features and run them through OneHotEncoder, define non-categorical features then merge them with encoded data\"\"\"\n",
    "\n",
    "def one_hot_encoder(df_train_test_values):\n",
    "    type_column = df_train_test_values[\"type\"].values   #convert 'type' to numpy array\n",
    "    ohe_column = [\"postalCode\"]   #declare categorical feaures\n",
    "    ohe = OneHotEncoder()   #declare OneHotEncoder\n",
    "    ohe_fit_transform = ohe.fit_transform(df_train_test_values[ohe_column]).toarray()   #fit-transform categorical features then convert to numpy array\n",
    "    ohe_data = np.column_stack((type_column, ohe_fit_transform))   #merge 'type' with encoded categorical features\n",
    "    joblib.dump(ohe, 'encoder.joblib')   #save onehotencoder to joblib\n",
    "    non_ohe_columns = [\"bedrooms\", \"buildingCondition\", \"kitchenType\", \"livingArea\", \"numberOfFrontages\"]   #declare non-categorical features\n",
    "    non_ohe_data = df_train_test_values[non_ohe_columns].values   #convert non-categorical features to numpy array\n",
    "    X = np.column_stack((ohe_data, non_ohe_data))   #merge data as X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to split X and y into train and test sets\"\"\"\n",
    "\n",
    "def split_data(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to scale the datasets\"\"\"\n",
    "\n",
    "def scaler(X_train, X_test):\n",
    "    sc = MinMaxScaler()   #declare scaler\n",
    "    X_train = sc.fit_transform(X_train)   #fit-transform X_train\n",
    "    X_test = sc.fit_transform(X_test)   #fit-transform X_test\n",
    "    joblib.dump(sc, 'scaler.joblib')   #save scaler to joblib\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to declare model, fit and evaluate\"\"\"\n",
    "\n",
    "def regression_model(X_train, X_test, y_train, y_test):\n",
    "    regressor = RandomForestRegressor(n_estimators= 100, random_state= 0)   #declare random forest regressor model\n",
    "    regressor.fit(X_train, y_train)   #fit training dataset\n",
    "    train_score = regressor.score(X_train, y_train)   #training score\n",
    "    test_score = regressor.score(X_test, y_test)   #test score\n",
    "    joblib.dump(regressor, 'model.joblib')   #save model to joblib\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is the modeling function\"\"\"\n",
    "\n",
    "def model(train_test_data):\n",
    "    df_train_test = load_train_test(train_test_data)   #load dataset\n",
    "    price = df_train_test[[\"price\"]]   #declare 'price' feature\n",
    "    df_train_test_features = train_test_features(df_train_test)   #remove features that won't be used in the model\n",
    "    df_train_test_values = train_test_values(df_train_test_features)   #transform train-test values\n",
    "    X = one_hot_encoder(df_train_test_values)   #declare X variable\n",
    "    y = price.values   #declare Y variable\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)   #split dataset\n",
    "    X_train, X_test = scaler(X_train, X_test)   #scale dataset\n",
    "    train_score, test_score = regression_model(X_train, X_test, y_train, y_test)   #run model\n",
    "    return train_score, test_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('immo_eliza')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a33f1ef1e9ec6c31820fe781c5813ed8dc5071af9cb6488d9d33ac3262f9cb66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
